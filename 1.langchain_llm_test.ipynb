{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.2.14-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting langchain-core<0.4.0,>=0.3.27 (from langchain-openai)\n",
      "  Downloading langchain_core-0.3.29-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting openai<2.0.0,>=1.58.1 (from langchain-openai)\n",
      "  Downloading openai-1.59.3-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
      "  Downloading tiktoken-0.8.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain-core<0.4.0,>=0.3.27->langchain-openai)\n",
      "  Using cached PyYAML-6.0.2-cp312-cp312-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.27->langchain-openai)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langsmith<0.3,>=0.1.125 (from langchain-core<0.4.0,>=0.3.27->langchain-openai)\n",
      "  Downloading langsmith-0.2.10-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in .\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-openai) (24.2)\n",
      "Collecting pydantic<3.0.0,>=2.5.2 (from langchain-core<0.4.0,>=0.3.27->langchain-openai)\n",
      "  Downloading pydantic-2.10.4-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<0.4.0,>=0.3.27->langchain-openai)\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting typing-extensions>=4.7 (from langchain-core<0.4.0,>=0.3.27->langchain-openai)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai<2.0.0,>=1.58.1->langchain-openai)\n",
      "  Downloading anyio-4.8.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai<2.0.0,>=1.58.1->langchain-openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai<2.0.0,>=1.58.1->langchain-openai)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.58.1->langchain-openai)\n",
      "  Downloading jiter-0.8.2-cp312-cp312-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting sniffio (from openai<2.0.0,>=1.58.1->langchain-openai)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>4 (from openai<2.0.0,>=1.58.1->langchain-openai)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 0.0/57.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 57.7/57.7 kB 3.2 MB/s eta 0:00:00\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain-openai)\n",
      "  Downloading regex-2024.11.6-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/41.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 41.5/41.5 kB ? eta 0:00:00\n",
      "Collecting requests>=2.26.0 (from tiktoken<1,>=0.7->langchain-openai)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting idna>=2.8 (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain-openai)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting certifi (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai)\n",
      "  Downloading certifi-2024.12.14-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai)\n",
      "  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.27->langchain-openai)\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-openai)\n",
      "  Downloading orjson-3.10.13-cp312-cp312-win_amd64.whl.metadata (42 kB)\n",
      "     ---------------------------------------- 0.0/42.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 42.9/42.9 kB 2.0 MB/s eta 0:00:00\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-openai)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.27->langchain-openai)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.27->langchain-openai)\n",
      "  Downloading pydantic_core-2.27.2-cp312-cp312-win_amd64.whl.metadata (6.7 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai)\n",
      "  Downloading charset_normalizer-3.4.1-cp312-cp312-win_amd64.whl.metadata (36 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai)\n",
      "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: colorama in .\\venv\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.58.1->langchain-openai) (0.4.6)\n",
      "Downloading langchain_openai-0.2.14-py3-none-any.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.9/50.9 kB 2.7 MB/s eta 0:00:00\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading langchain_core-0.3.29-py3-none-any.whl (411 kB)\n",
      "   ---------------------------------------- 0.0/411.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 411.6/411.6 kB 25.1 MB/s eta 0:00:00\n",
      "Downloading openai-1.59.3-py3-none-any.whl (454 kB)\n",
      "   ---------------------------------------- 0.0/454.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 454.8/454.8 kB 27.8 MB/s eta 0:00:00\n",
      "Downloading tiktoken-0.8.0-cp312-cp312-win_amd64.whl (883 kB)\n",
      "   ---------------------------------------- 0.0/883.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 883.8/883.8 kB 28.2 MB/s eta 0:00:00\n",
      "Downloading anyio-4.8.0-py3-none-any.whl (96 kB)\n",
      "   ---------------------------------------- 0.0/96.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 96.0/96.0 kB 5.4 MB/s eta 0:00:00\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "   ---------------------------------------- 0.0/73.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 73.5/73.5 kB 4.0 MB/s eta 0:00:00\n",
      "Downloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.6/78.6 kB ? eta 0:00:00\n",
      "Downloading jiter-0.8.2-cp312-cp312-win_amd64.whl (204 kB)\n",
      "   ---------------------------------------- 0.0/204.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 204.7/204.7 kB ? eta 0:00:00\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langsmith-0.2.10-py3-none-any.whl (326 kB)\n",
      "   ---------------------------------------- 0.0/326.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 326.4/326.4 kB 10.2 MB/s eta 0:00:00\n",
      "Downloading pydantic-2.10.4-py3-none-any.whl (431 kB)\n",
      "   ---------------------------------------- 0.0/431.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 431.8/431.8 kB 28.1 MB/s eta 0:00:00\n",
      "Downloading pydantic_core-2.27.2-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------  2.0/2.0 MB 42.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 9.7 MB/s eta 0:00:00\n",
      "Using cached PyYAML-6.0.2-cp312-cp312-win_amd64.whl (156 kB)\n",
      "Downloading regex-2024.11.6-cp312-cp312-win_amd64.whl (273 kB)\n",
      "   ---------------------------------------- 0.0/273.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 273.6/273.6 kB ? eta 0:00:00\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.5/78.5 kB 4.3 MB/s eta 0:00:00\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading certifi-2024.12.14-py3-none-any.whl (164 kB)\n",
      "   ---------------------------------------- 0.0/164.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 164.9/164.9 kB 9.7 MB/s eta 0:00:00\n",
      "Downloading charset_normalizer-3.4.1-cp312-cp312-win_amd64.whl (102 kB)\n",
      "   ---------------------------------------- 0.0/102.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 102.8/102.8 kB ? eta 0:00:00\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading orjson-3.10.13-cp312-cp312-win_amd64.whl (135 kB)\n",
      "   ---------------------------------------- 0.0/135.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 135.2/135.2 kB 8.3 MB/s eta 0:00:00\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "   ---------------------------------------- 0.0/128.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 128.4/128.4 kB 7.9 MB/s eta 0:00:00\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: urllib3, typing-extensions, tqdm, tenacity, sniffio, regex, PyYAML, python-dotenv, orjson, jsonpointer, jiter, idna, h11, distro, charset-normalizer, certifi, annotated-types, requests, pydantic-core, jsonpatch, httpcore, anyio, tiktoken, requests-toolbelt, pydantic, httpx, openai, langsmith, langchain-core, langchain-openai\n",
      "Successfully installed PyYAML-6.0.2 annotated-types-0.7.0 anyio-4.8.0 certifi-2024.12.14 charset-normalizer-3.4.1 distro-1.9.0 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 idna-3.10 jiter-0.8.2 jsonpatch-1.33 jsonpointer-3.0.0 langchain-core-0.3.29 langchain-openai-0.2.14 langsmith-0.2.10 openai-1.59.3 orjson-3.10.13 pydantic-2.10.4 pydantic-core-2.27.2 python-dotenv-1.0.1 regex-2024.11.6 requests-2.32.3 requests-toolbelt-1.0.0 sniffio-1.3.1 tenacity-9.0.0 tiktoken-0.8.0 tqdm-4.67.1 typing-extensions-4.12.2 urllib3-2.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain-openai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[1;32m----> 2\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mChatOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m ai_message \u001b[38;5;241m=\u001b[39m llm\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m인프런에는 어떤강의들이 있나요?\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m ai_message\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[1;32md:\\vscode\\llm\\venv\\Lib\\site-packages\\langchain_core\\load\\serializable.py:125\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32md:\\vscode\\llm\\venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:578\u001b[0m, in \u001b[0;36mBaseChatOpenAI.validate_environment\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    576\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp_client \u001b[38;5;241m=\u001b[39m httpx\u001b[38;5;241m.\u001b[39mClient(proxy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopenai_proxy)\n\u001b[0;32m    577\u001b[0m     sync_specific \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp_client\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp_client}\n\u001b[1;32m--> 578\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_client \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mclient_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msync_specific\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    579\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\n\u001b[0;32m    580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masync_client:\n",
      "File \u001b[1;32md:\\vscode\\llm\\venv\\Lib\\site-packages\\openai\\_client.py:110\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[1;34m(self, api_key, organization, project, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[0;32m    108\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 110\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[0;32m    111\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    112\u001b[0m     )\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m api_key\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m organization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI()\n",
    "ai_message = llm.invoke('인프런에는 어떤강의들이 있나요?')\n",
    "ai_message.content\n",
    "\n",
    "'''\n",
    ".env에서 OPENAI_API_KEY로 세팅 X 경우\n",
    "import os\n",
    "api_key = os.getenv(\"OPENAI_KEY\")\n",
    "llm = ChatOpenAI(api_key=api_key)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in .\\venv\\lib\\site-packages (1.0.1)\n",
      "Collecting langchain-upstage\n",
      "  Downloading langchain_upstage-0.4.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: langchain-core<0.4,>=0.3.0 in .\\venv\\lib\\site-packages (from langchain-upstage) (0.3.29)\n",
      "Requirement already satisfied: langchain-openai<0.3,>=0.2 in .\\venv\\lib\\site-packages (from langchain-upstage) (0.2.14)\n",
      "Collecting pypdf<5.0.0,>=4.2.0 (from langchain-upstage)\n",
      "  Downloading pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in .\\venv\\lib\\site-packages (from langchain-upstage) (2.32.3)\n",
      "Collecting tokenizers<0.20.0,>=0.19.1 (from langchain-upstage)\n",
      "  Downloading tokenizers-0.19.1-cp312-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in .\\venv\\lib\\site-packages (from langchain-core<0.4,>=0.3.0->langchain-upstage) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in .\\venv\\lib\\site-packages (from langchain-core<0.4,>=0.3.0->langchain-upstage) (1.33)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.125 in .\\venv\\lib\\site-packages (from langchain-core<0.4,>=0.3.0->langchain-upstage) (0.2.10)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in .\\venv\\lib\\site-packages (from langchain-core<0.4,>=0.3.0->langchain-upstage) (24.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in .\\venv\\lib\\site-packages (from langchain-core<0.4,>=0.3.0->langchain-upstage) (2.10.4)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in .\\venv\\lib\\site-packages (from langchain-core<0.4,>=0.3.0->langchain-upstage) (9.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in .\\venv\\lib\\site-packages (from langchain-core<0.4,>=0.3.0->langchain-upstage) (4.12.2)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.58.1 in .\\venv\\lib\\site-packages (from langchain-openai<0.3,>=0.2->langchain-upstage) (1.59.3)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in .\\venv\\lib\\site-packages (from langchain-openai<0.3,>=0.2->langchain-upstage) (0.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in .\\venv\\lib\\site-packages (from requests<3.0.0,>=2.31.0->langchain-upstage) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in .\\venv\\lib\\site-packages (from requests<3.0.0,>=2.31.0->langchain-upstage) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in .\\venv\\lib\\site-packages (from requests<3.0.0,>=2.31.0->langchain-upstage) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in .\\venv\\lib\\site-packages (from requests<3.0.0,>=2.31.0->langchain-upstage) (2024.12.14)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from tokenizers<0.20.0,>=0.19.1->langchain-upstage)\n",
      "  Downloading huggingface_hub-0.27.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting filelock (from huggingface-hub<1.0,>=0.16.4->tokenizers<0.20.0,>=0.19.1->langchain-upstage)\n",
      "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.16.4->tokenizers<0.20.0,>=0.19.1->langchain-upstage)\n",
      "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in .\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<0.20.0,>=0.19.1->langchain-upstage) (4.67.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in .\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3.0->langchain-upstage) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in .\\venv\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-upstage) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in .\\venv\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-upstage) (3.10.13)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in .\\venv\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-upstage) (1.0.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in .\\venv\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain-openai<0.3,>=0.2->langchain-upstage) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in .\\venv\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain-openai<0.3,>=0.2->langchain-upstage) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in .\\venv\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain-openai<0.3,>=0.2->langchain-upstage) (0.8.2)\n",
      "Requirement already satisfied: sniffio in .\\venv\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain-openai<0.3,>=0.2->langchain-upstage) (1.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in .\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3.0->langchain-upstage) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in .\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3.0->langchain-upstage) (2.27.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in .\\venv\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai<0.3,>=0.2->langchain-upstage) (2024.11.6)\n",
      "Requirement already satisfied: httpcore==1.* in .\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-upstage) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in .\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-upstage) (0.14.0)\n",
      "Requirement already satisfied: colorama in .\\venv\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub<1.0,>=0.16.4->tokenizers<0.20.0,>=0.19.1->langchain-upstage) (0.4.6)\n",
      "Downloading langchain_upstage-0.4.0-py3-none-any.whl (26 kB)\n",
      "Downloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
      "   ---------------------------------------- 0.0/295.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 295.8/295.8 kB 9.2 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.19.1-cp312-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ----------------------------- ---------- 1.6/2.2 MB 34.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 28.3 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.27.0-py3-none-any.whl (450 kB)\n",
      "   ---------------------------------------- 0.0/450.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 450.5/450.5 kB 29.4 MB/s eta 0:00:00\n",
      "Downloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "   ---------------------------------------- 0.0/183.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 183.9/183.9 kB 10.9 MB/s eta 0:00:00\n",
      "Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: pypdf, fsspec, filelock, huggingface-hub, tokenizers, langchain-upstage\n",
      "Successfully installed filelock-3.16.1 fsspec-2024.12.0 huggingface-hub-0.27.0 langchain-upstage-0.4.0 pypdf-4.3.1 tokenizers-0.19.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv langchain-upstage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://console.upstage.ai/docs/getting-started/quick-start\n",
    "from langchain_upstage import ChatUpstage\n",
    "from langchain_core.messages import HumanMessage\n",
    "import httpx\n",
    "client = httpx.Client(verify=False)  # SSL 인증 무시\n",
    "llm = ChatUpstage(model=\"solar-pro\", http_client = client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '안녕 오늘 서울 날씨 어때?', 'role': 'user'}], 'model': 'solar-pro', 'n': 1, 'stream': False, 'temperature': 0.7}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions\n",
      "DEBUG:httpcore.connection:close.started\n",
      "DEBUG:httpcore.connection:close.complete\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.upstage.ai' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000023FB9B9DF10>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x0000023FC14ECA50> server_hostname='api.upstage.ai' timeout=None\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000023FC1200C20>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 06 Jan 2025 01:08:15 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'503'), (b'Connection', b'keep-alive'), (b'Access-Control-Allow-Headers', b'*'), (b'Access-Control-Allow-Methods', b'OPTIONS,GET,POST'), (b'Access-Control-Allow-Origin', b'*')])\n",
      "INFO:httpx:HTTP Request: POST https://api.upstage.ai/v1/solar/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.upstage.ai/v1/solar/chat/completions \"200 OK\" Headers({'date': 'Mon, 06 Jan 2025 01:08:15 GMT', 'content-type': 'application/json', 'content-length': '503', 'connection': 'keep-alive', 'access-control-allow-headers': '*', 'access-control-allow-methods': 'OPTIONS,GET,POST', 'access-control-allow-origin': '*'})\n",
      "DEBUG:openai._base_client:request_id: None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'오늘 서울의 날씨는 대체로 맑고, 기온은 최고 23도, 최저 12도로 예상됩니다. 야외 활동을 즐기기에 좋은 날씨이니, 즐기시기 바랍니다!'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    HumanMessage(content =\"안녕 오늘 서울 날씨 어때?\")\n",
    "]\n",
    "response = llm.invoke(messages)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
